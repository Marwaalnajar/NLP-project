{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e7baa15-ffee-420c-bcdc-0d8fe1e05fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data folder: /Users/marwa/Desktop/Task_A\n",
      "Files in folder: ['train.parquet', 'test.parquet', 'test_sample.parquet', 'validation.parquet', 'sample_submission.csv']\n",
      "Train: (500000, 4)\n",
      "Val: (100000, 4)\n",
      "Test: (1000, 2)\n",
      "Test_sample: (1000, 4)\n",
      "\n",
      "================ HYPERPARAMETER SEARCH ==================\n",
      "\n",
      "Training config: 3_5_200k_a1e-4\n",
      "  Val Accuracy : 0.9326\n",
      "  Val Macro F1 : 0.9326\n",
      "\n",
      "Training config: 3_5_150k_a1e-4\n",
      "  Val Accuracy : 0.9330\n",
      "  Val Macro F1 : 0.9329\n",
      "\n",
      "Training config: 3_4_150k_a5e-5\n",
      "  Val Accuracy : 0.9409\n",
      "  Val Macro F1 : 0.9408\n",
      "\n",
      "Training config: 3_5_200k_a5e-4\n",
      "  Val Accuracy : 0.8969\n",
      "  Val Macro F1 : 0.8969\n",
      "\n",
      "===== Validation Results (sorted by Macro F1) =====\n",
      "3_4_150k_a5e-5: Macro F1=0.9408, Accuracy=0.9409, ngram=(3, 4), max_features=150000, alpha=5e-05\n",
      "3_5_150k_a1e-4: Macro F1=0.9329, Accuracy=0.9330, ngram=(3, 5), max_features=150000, alpha=0.0001\n",
      "3_5_200k_a1e-4: Macro F1=0.9326, Accuracy=0.9326, ngram=(3, 5), max_features=200000, alpha=0.0001\n",
      "3_5_200k_a5e-4: Macro F1=0.8969, Accuracy=0.8969, ngram=(3, 5), max_features=200000, alpha=0.0005\n",
      "\n",
      "Best config selected: {'name': '3_4_150k_a5e-5', 'ngram': (3, 4), 'max': 150000, 'alpha': 5e-05, 'val_acc': 0.94088, 'val_f1': 0.9408405600341754}\n",
      "\n",
      "================ FINAL TRAINING ON TRAIN+VAL ==================\n",
      "\n",
      "Final model saved as: /Users/marwa/Desktop/Task_A/subtaskA_sgd_3_4_150k_a5e-5.joblib\n",
      "\n",
      "================ TEST_SAMPLE EVALUATION ==================\n",
      "\n",
      "Test_sample Accuracy : 0.3170\n",
      "Test_sample Macro F1 : 0.3091\n",
      "\n",
      "Classification report on test_sample:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.14      0.24       777\n",
      "           1       0.24      0.95      0.38       223\n",
      "\n",
      "    accuracy                           0.32      1000\n",
      "   macro avg       0.57      0.54      0.31      1000\n",
      "weighted avg       0.76      0.32      0.27      1000\n",
      "\n",
      "\n",
      "================ GENERATING SUBMISSION FILE ==================\n",
      "\n",
      "Submission file created: /Users/marwa/Desktop/Task_A/submission_subtaskA_3_4_150k_a5e-5.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Subtask A — TF-IDF + SGDClassifier (Full Version)\n",
    "------------------------------------------------\n",
    "• Binary authorship attribution (0 = human, 1 = machine)\n",
    "• Uses train/validation/test/test_sample/sample_submission from Task_A folder\n",
    "• Hyperparameter search on validation set\n",
    "• Retrain final model on train+val\n",
    "• Save model + generate submission.csv\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# ================================================================\n",
    "# 1. Folder containing the files on your Desktop\n",
    "# ================================================================\n",
    "DATA_DIR = \"/Users/marwa/Desktop/Task_A\"   # <--   Task_A Folder\n",
    "\n",
    "print(\"Using data folder:\", DATA_DIR)\n",
    "print(\"Files in folder:\", os.listdir(DATA_DIR))  # Check Files\n",
    "\n",
    "# ================================================================\n",
    "# 2. Load data from competition files\n",
    "#   train.parquet, validation.parquet, test.parquet,\n",
    "#   test_sample.parquet, sample_submission.csv\n",
    "# ================================================================\n",
    "train = pd.read_parquet(os.path.join(DATA_DIR, \"train.parquet\"))\n",
    "val = pd.read_parquet(os.path.join(DATA_DIR, \"validation.parquet\"))\n",
    "test = pd.read_parquet(os.path.join(DATA_DIR, \"test.parquet\"))\n",
    "test_sample = pd.read_parquet(os.path.join(DATA_DIR, \"test_sample.parquet\"))\n",
    "sample_sub = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Val:\", val.shape)\n",
    "print(\"Test:\", test.shape)\n",
    "print(\"Test_sample:\", test_sample.shape)\n",
    "\n",
    "# ================================================================\n",
    "# 3. Ensure labels are ints (binary: 0 = human, 1 = machine)\n",
    "# ================================================================\n",
    "train[\"label\"] = train[\"label\"].astype(int)\n",
    "val[\"label\"] = val[\"label\"].astype(int)\n",
    "test_sample[\"label\"] = test_sample[\"label\"].astype(int)\n",
    "\n",
    "# ================================================================\n",
    "# 4. Build text (language + code)\n",
    "# ================================================================\n",
    "def make_text(df: pd.DataFrame) -> pd.Series:\n",
    "    code = df[\"code\"].fillna(\"\")\n",
    "    if \"language\" in df.columns:\n",
    "        lang = df[\"language\"].fillna(\"\")\n",
    "        return lang + \" \" + code\n",
    "    return code\n",
    "\n",
    "X_train = make_text(train)\n",
    "X_val   = make_text(val)\n",
    "X_test  = make_text(test)\n",
    "X_ts    = make_text(test_sample)\n",
    "\n",
    "y_train = train[\"label\"].values\n",
    "y_val   = val[\"label\"].values\n",
    "y_ts    = test_sample[\"label\"].values\n",
    "\n",
    "# ================================================================\n",
    "# 5. Pipeline builder\n",
    "# ================================================================\n",
    "def build_model(\n",
    "    ngram=(3, 5),\n",
    "    max_features=200_000,\n",
    "    alpha=1e-4,\n",
    "    loss=\"hinge\"\n",
    ") -> Pipeline:\n",
    "    return Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=ngram,\n",
    "            max_features=max_features,\n",
    "            min_df=10,\n",
    "        )),\n",
    "        (\"clf\", SGDClassifier(\n",
    "            loss=loss,              # \"hinge\" = linear SVM\n",
    "            alpha=alpha,\n",
    "            max_iter=10_000,\n",
    "            tol=1e-3,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "# ================================================================\n",
    "# 6. Hyperparameter search on validation set\n",
    "# ================================================================\n",
    "configs = [\n",
    "    {\"name\": \"3_5_200k_a1e-4\", \"ngram\": (3, 5), \"max\": 200_000, \"alpha\": 1e-4},\n",
    "    {\"name\": \"3_5_150k_a1e-4\", \"ngram\": (3, 5), \"max\": 150_000, \"alpha\": 1e-4},\n",
    "    {\"name\": \"3_4_150k_a5e-5\", \"ngram\": (3, 4), \"max\": 150_000, \"alpha\": 5e-5},\n",
    "    {\"name\": \"3_5_200k_a5e-4\", \"ngram\": (3, 5), \"max\": 200_000, \"alpha\": 5e-4},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n================ HYPERPARAMETER SEARCH ==================\\n\")\n",
    "for cfg in configs:\n",
    "    print(\"Training config:\", cfg[\"name\"])\n",
    "\n",
    "    model = build_model(\n",
    "        ngram=cfg[\"ngram\"],\n",
    "        max_features=cfg[\"max\"],\n",
    "        alpha=cfg[\"alpha\"],\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    macro_f1 = f1_score(y_val, val_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"  Val Accuracy : {acc:.4f}\")\n",
    "    print(f\"  Val Macro F1 : {macro_f1:.4f}\\n\")\n",
    "\n",
    "    cfg[\"val_acc\"] = acc\n",
    "    cfg[\"val_f1\"] = macro_f1\n",
    "    results.append(cfg)\n",
    "\n",
    "# Sort configs by macro F1 (descending)\n",
    "results = sorted(results, key=lambda d: d[\"val_f1\"], reverse=True)\n",
    "best = results[0]\n",
    "\n",
    "print(\"===== Validation Results (sorted by Macro F1) =====\")\n",
    "for r in results:\n",
    "    print(\n",
    "        f\"{r['name']}: Macro F1={r['val_f1']:.4f}, \"\n",
    "        f\"Accuracy={r['val_acc']:.4f}, \"\n",
    "        f\"ngram={r['ngram']}, max_features={r['max']}, alpha={r['alpha']}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nBest config selected:\", best)\n",
    "\n",
    "# ================================================================\n",
    "# 7. Retrain final model on (train + validation)\n",
    "# ================================================================\n",
    "print(\"\\n================ FINAL TRAINING ON TRAIN+VAL ==================\\n\")\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_full = np.concatenate([y_train, y_val])\n",
    "\n",
    "final_model = build_model(\n",
    "    ngram=best[\"ngram\"],\n",
    "    max_features=best[\"max\"],\n",
    "    alpha=best[\"alpha\"],\n",
    ")\n",
    "\n",
    "final_model.fit(X_full, y_full)\n",
    "\n",
    "model_filename = f\"subtaskA_sgd_{best['name']}.joblib\"\n",
    "model_path = os.path.join(DATA_DIR, model_filename)\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"Final model saved as: {model_path}\")\n",
    "\n",
    "# ================================================================\n",
    "# 8. Evaluate on test_sample (local diagnostics)\n",
    "# ================================================================\n",
    "print(\"\\n================ TEST_SAMPLE EVALUATION ==================\\n\")\n",
    "\n",
    "ts_pred = final_model.predict(X_ts)\n",
    "ts_acc = accuracy_score(y_ts, ts_pred)\n",
    "ts_macro_f1 = f1_score(y_ts, ts_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Test_sample Accuracy : {ts_acc:.4f}\")\n",
    "print(f\"Test_sample Macro F1 : {ts_macro_f1:.4f}\\n\")\n",
    "print(\"Classification report on test_sample:\\n\")\n",
    "print(classification_report(y_ts, ts_pred))\n",
    "\n",
    "# ================================================================\n",
    "# 9. Predict on real test set and create submission file\n",
    "# ================================================================\n",
    "print(\"\\n================ GENERATING SUBMISSION FILE ==================\\n\")\n",
    "\n",
    "test_pred = final_model.predict(X_test)\n",
    "sample_sub[\"label\"] = test_pred\n",
    "\n",
    "submission_name = f\"submission_subtaskA_{best['name']}.csv\"\n",
    "submission_path = os.path.join(DATA_DIR, submission_name)\n",
    "sample_sub.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission file created: {submission_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b2df9-e3a8-4727-b921-1e492c88d757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e62304-b5be-4ad3-b7ef-68e8c2e0ce4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
